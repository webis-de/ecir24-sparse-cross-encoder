{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/allenai/longformer/master/longformer/lib/lib_diagonaled_mm_float32_cuda.so -O lib_diagonaled_mm_float32_cuda.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1dwUVNPIP7Z"
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import time\n",
    "from functools import lru_cache, partial, reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from copy import deepcopy\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "import torch\n",
    "import os.path\n",
    "import window_matmul\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from torch.profiler import profile, ProfilerActivity\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.extend([\"../..\"])\n",
    "from listformer.model.listformer import ListformerModel, ListformerConfig\n",
    "\n",
    "if \"SLURM_JOB_ID\" in os.environ:\n",
    "    del os.environ[\"SLURM_JOB_ID\"]\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DfJDU3z29Af"
   },
   "outputs": [],
   "source": [
    "from aquarel import Theme\n",
    "\n",
    "theme = Theme(name=\"theme\").set_grid(draw=True).set_font(family=\"serif\")\n",
    "theme.apply()\n",
    "\n",
    "markers = [\"o\", \"s\", \"X\", \"v\", \"P\", \"*\", \"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_readable_bytes(sizes, unit=None):\n",
    "    units = ['B', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB']\n",
    "    if unit is None:\n",
    "        unit_idx = 0\n",
    "        for size in sizes:\n",
    "            index = 0\n",
    "            while size >= 1024 and index < len(units) - 1:\n",
    "                size /= 1024\n",
    "                index += 1\n",
    "            unit_idx = max(index, unit_idx)\n",
    "    else:\n",
    "        unit_idx = units.index(unit)\n",
    "    sizes = [size / 1024**unit_idx for size in sizes]\n",
    "    return sizes, units[unit_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSNS18wVHG7O"
   },
   "outputs": [],
   "source": [
    "class DiagonaledMM(torch.autograd.Function):\n",
    "    '''Class to encapsulate tvm code for compiling a diagonal_mm function, in addition to calling\n",
    "    this function from PyTorch\n",
    "    '''\n",
    "\n",
    "    function_dict = {}  # save a list of functions, each has a different set of parameters\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_lib_filename(dtype: str, device: str):\n",
    "        base_filename = 'lib_diagonaled_mm'\n",
    "        return '{}_{}_{}.so'.format(base_filename, dtype, device)\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_compiled_function(dtype: str, device: str):\n",
    "        from tvm.runtime import load_module  # this can be the small runtime python library, and doesn't need to be the whole thing\n",
    "        filename = DiagonaledMM._get_lib_filename(dtype, device)\n",
    "        return load_module(filename)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_function(dtype: str, device: str):\n",
    "        '''Loads the function from the disk or compile it'''\n",
    "        # A list of arguments that define the function\n",
    "        args = (dtype, device)\n",
    "        if args not in DiagonaledMM.function_dict:\n",
    "            diagonaled_mm = DiagonaledMM._load_compiled_function(dtype, device)  # try to load from disk\n",
    "            # convert the tvm function into a pytorch function\n",
    "            from tvm.contrib import dlpack\n",
    "            diagonaled_mm_pytorch = dlpack.to_pytorch_func(diagonaled_mm)  # wrap it as a pytorch function\n",
    "            # save the function into a dictionary to be reused\n",
    "            DiagonaledMM.function_dict[args] = diagonaled_mm_pytorch  # save it in a dictionary for next time\n",
    "        return DiagonaledMM.function_dict[args]\n",
    "\n",
    "    @staticmethod\n",
    "    def _diagonaled_mm(t1: torch.Tensor, t2: torch.Tensor, w: int, d: Union[torch.Tensor,int],\n",
    "                       is_t1_diagonaled: bool = False, transpose_t1: bool = False, padding: int = 0,\n",
    "                       autoregressive: bool = False):\n",
    "        '''Calls the compiled function after checking the input format. This function is called in three different modes.\n",
    "        t1 x t2 = r ==> t1 and t2 are not diagonaled, but r is. Useful for query x key = attention_scores\n",
    "        t1 x t2 = r ==> t1 is diagonaled, but t2 and r are not. Useful to compuate attantion_scores x value = context\n",
    "        t1 x t2 = r ==> t1 is diagonaled and it should be transposed, but t2 and r are not diagonaled. Useful in some of\n",
    "                            the calculations in the backward pass.\n",
    "        '''\n",
    "        dtype = str(t1.dtype).split('.')[1]\n",
    "        device = t1.device.type\n",
    "        assert len(t1.shape) == 4\n",
    "        assert len(t1.shape) == len(t2.shape)\n",
    "        assert t1.shape[:3] == t2.shape[:3]\n",
    "        if isinstance(d, int):  # if d is an integer, replace it with a tensor of the same length\n",
    "                                # as number of heads, and it is filled with the same dilation value\n",
    "            d = t1.new_full(size=(t1.shape[2],), fill_value=d, dtype=torch.int, requires_grad=False)\n",
    "\n",
    "        assert len(d.shape) == 1\n",
    "        assert d.shape[0] == t1.shape[2]  # number of dilation scores should match number of heads\n",
    "        b = t1.shape[0]  # batch size\n",
    "        n = t1.shape[1]  # sequence length\n",
    "        h = t1.shape[2]  # number of heads\n",
    "        m = t2.shape[3]  # hidden dimension\n",
    "        w_upper = 0 if autoregressive else w\n",
    "        c = w_upper + w + 1  # number of diagonals\n",
    "        if is_t1_diagonaled:\n",
    "            assert t1.shape[3] == c\n",
    "            r = t1.new_empty(b, n, h, m)  # allocate spase for the result tensor\n",
    "        else:\n",
    "            assert not transpose_t1\n",
    "            assert t1.shape[3] == m\n",
    "            r = t1.new_empty(b, n, h, c)  # allocate spase for the result tensor\n",
    "\n",
    "        # gets function from memory, from disk or compiles it from scratch\n",
    "        _diagonaled_mm_function = DiagonaledMM._get_function(dtype=dtype, device=device)\n",
    "\n",
    "        # The last argument to this function is a little hacky. It is the size of the last dimension of the result tensor\n",
    "        # We use it as a proxy to tell if t1_is_diagonaled or not (if t1 is diagonaled, result is not, and vice versa).\n",
    "        # The second reason is that the lambda expression in `_compile_function` is easier to express when the shape\n",
    "        # of the output is known\n",
    "        # This functions computes diagonal_mm then saves the result in `r`\n",
    "        if m == c:\n",
    "            # FIXME\n",
    "            print('Error: the hidden dimension {m} shouldn\\'t match number of diagonals {c}')\n",
    "            assert False\n",
    "        _diagonaled_mm_function(t1, t2, r, d, w, w_upper, padding, transpose_t1, m if is_t1_diagonaled else c)\n",
    "        return r\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_tensors(t):\n",
    "        '''Fix `stride()` information of input tensor. This addresses some inconsistency in stride information in PyTorch.\n",
    "        For a tensor t, if t.size(0) == 1, then the value of t.stride()[0] doesn't matter.\n",
    "        TVM expects this value to be the `product(t.size()[1:])` but PyTorch some times sets it to `t.stride()[1]`.\n",
    "        Here's an example to reporduce this issue:\n",
    "            import torch\n",
    "            print(torch.randn(1, 10).stride())\n",
    "            > (10, 1)\n",
    "            print(torch.randn(10, 1).t().contiguous().stride())\n",
    "            > (1, 1)  # expected it to be (10, 1) as above\n",
    "            print(torch.randn(10, 2).t().contiguous().stride())\n",
    "            > (10, 1) # but gets the expected stride if the first dimension is > 1\n",
    "        '''\n",
    "        assert t.is_contiguous()\n",
    "        t_stride = list(t.stride())\n",
    "        t_size = list(t.size())\n",
    "        # Fix wrong stride information for the first dimension. This occures when batch_size=1\n",
    "        if t_size[0] == 1 and t_stride[0] == t_stride[1]:\n",
    "            # In this case, the stride of the first dimension should be the product\n",
    "            # of the sizes  of all other dimensions\n",
    "            t_stride[0] = t_size[1] * t_size[2] * t_size[3]\n",
    "            t = t.as_strided(size=t_size, stride=t_stride)\n",
    "        return t\n",
    "\n",
    "    min_seq_len = 16  # unexpected output if seq_len < 16\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, t1: torch.Tensor, t2: torch.Tensor, w: int, d: Union[torch.Tensor,int], is_t1_diagonaled: bool = False, padding: int = 0, autoregressive: bool = False) -> torch.Tensor:\n",
    "        '''Compuates diagonal_mm of t1 and t2.\n",
    "        args: \n",
    "        t1: torch.Tensor = (batch_size, seq_len, num_attention_heads, hidden_size|number_of_diagonals).\n",
    "            t1 can be a regular tensor (e.g. `query_layer`) or a diagonaled one (e.g. `attention_scores`)\n",
    "        t2: torch.Tensor = (batch_size, seq_len, num_attention_heads, hidden_size). This is always a non-diagonaled\n",
    "            tensor, e.g. `key_layer` or `value_layer`\n",
    "        w: int = window size; number of attentions on each side of the word\n",
    "        d: torch.Tensor or int = dilation of attentions per attention head. If int, the same dilation value will be used for all\n",
    "            heads. If torch.Tensor, it should be 1D of lenth=number of attention heads\n",
    "        is_t1_diagonaled: is t1 a diagonaled or a regular tensor\n",
    "        padding: the padding value to use when accessing invalid locations. This is mainly useful when the padding\n",
    "            needs to be a very large negative value (to compute softmax of attentions). For other usecases,\n",
    "            please use zero padding.\n",
    "        autoregressive: if true, return only the lower triangle\n",
    "        returns: torch.Tensor = (batch_size, seq_len, num_attention_heads, hidden_size|number_of_diagonals)\n",
    "            if t1 is diagonaed, result is non-diagonaled, and vice versa\n",
    "        '''\n",
    "        batch_size, seq_len, num_attention_heads, hidden_size = t1.size()\n",
    "        assert seq_len >= DiagonaledMM.min_seq_len, 'avoid splitting errors by using seq_len >= {}'.format(DiagonaledMM.min_seq_len)  # FIXME\n",
    "        ctx.save_for_backward(t1, t2)\n",
    "        ctx.w = w\n",
    "        ctx.d = d\n",
    "        ctx.is_t1_diagonaled = is_t1_diagonaled\n",
    "        ctx.autoregressive = autoregressive\n",
    "        t1 = DiagonaledMM._prepare_tensors(t1)\n",
    "        t2 = DiagonaledMM._prepare_tensors(t2)\n",
    "        # output = t1.mm(t2)  # what would have been called if this was a regular matmul\n",
    "        output = DiagonaledMM._diagonaled_mm(t1, t2, w, d, is_t1_diagonaled=is_t1_diagonaled, padding=padding, autoregressive=autoregressive)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        t1, t2 = ctx.saved_tensors\n",
    "        w = ctx.w\n",
    "        d = ctx.d\n",
    "        is_t1_diagonaled = ctx.is_t1_diagonaled\n",
    "        autoregressive = ctx.autoregressive\n",
    "        if not grad_output.is_contiguous():\n",
    "            grad_output = grad_output.contiguous()  # tvm requires all input tensors to be contiguous\n",
    "        grad_output = DiagonaledMM._prepare_tensors(grad_output)\n",
    "        t1 = DiagonaledMM._prepare_tensors(t1)\n",
    "        t2 = DiagonaledMM._prepare_tensors(t2)\n",
    "        # http://cs231n.github.io/optimization-2/\n",
    "        # https://pytorch.org/docs/master/notes/extending.html\n",
    "        # grad_t1 = grad_output.mm(t2)  # what would have been called if this was a regular matmul\n",
    "        grad_t1 = DiagonaledMM._diagonaled_mm(grad_output, t2, w, d, is_t1_diagonaled=not is_t1_diagonaled, autoregressive=autoregressive)\n",
    "        # grad_t2 = grad_output.t().mm(t1)  # or `grad_t2 = t1.t().mm(grad_output).t()` because `(AB)^T = B^TA^T`\n",
    "        if is_t1_diagonaled:\n",
    "            grad_t2 = DiagonaledMM._diagonaled_mm(t1, grad_output, w, d, is_t1_diagonaled=True, transpose_t1=True, autoregressive=autoregressive)\n",
    "        else:\n",
    "            grad_t2 = DiagonaledMM._diagonaled_mm(grad_output, t1, w, d, is_t1_diagonaled=True, transpose_t1=True, autoregressive=autoregressive)\n",
    "        return grad_t1, grad_t2, None, None, None, None, None\n",
    "\n",
    "longformer_tvm_matmul = DiagonaledMM.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpnIhBAj_91E"
   },
   "outputs": [],
   "source": [
    "def _skew(x, direction, padding_value):\n",
    "    '''Convert diagonals into columns (or columns into diagonals depending on `direction`'''\n",
    "    x_padded = F.pad(x, direction, value=padding_value)\n",
    "    x_padded = x_padded.view(*x_padded.size()[:-2], x_padded.size(-1), x_padded.size(-2))\n",
    "    return x_padded\n",
    "\n",
    "\n",
    "def _skew2(x, padding_value):\n",
    "    '''shift every row 1 step to right converting columns into diagonals'''\n",
    "    # X = B x C x M x L\n",
    "    B, C, M, L = x.size()\n",
    "    x = F.pad(x, (0, M + 1), value=padding_value)  # B x C x M x (L+M+1)\n",
    "    x = x.view(B, C, -1)  # B x C x ML+MM+M\n",
    "    x = x[:, :, :-M]  # B x C x ML+MM\n",
    "    x = x.view(B, C, M, M + L)  # B x C, M x L+M\n",
    "    x = x[:, :, :, :-1]\n",
    "    return x\n",
    "\n",
    "\n",
    "def _chunk(x, w):\n",
    "    '''convert into overlapping chunkings. Chunk size = 2w, overlap size = w'''\n",
    "\n",
    "    # non-overlapping chunks of size = 2w\n",
    "    x = x.view(x.size(0), x.size(1) // (w * 2), w * 2, x.size(2))\n",
    "\n",
    "    # use `as_strided` to make the chunks overlap with an overlap size = w\n",
    "    chunk_size = list(x.size())\n",
    "    chunk_size[1] = chunk_size[1] * 2 - 1\n",
    "\n",
    "    chunk_stride = list(x.stride())\n",
    "    chunk_stride[1] = chunk_stride[1] // 2\n",
    "    return x.as_strided(size=chunk_size, stride=chunk_stride)\n",
    "\n",
    "\n",
    "def sliding_chunks_matmul_qk(q: torch.Tensor, k: torch.Tensor, w: int, padding_value: float):\n",
    "    '''Matrix multiplicatio of query x key tensors using with a sliding window attention pattern.\n",
    "    This implementation splits the input into overlapping chunks of size 2w (e.g. 512 for pretrained Longformer)\n",
    "    with an overlap of size w'''\n",
    "    bsz, seqlen, num_heads, head_dim = q.size()\n",
    "    assert seqlen % (w * 2) == 0\n",
    "    assert q.size() == k.size()\n",
    "\n",
    "    chunks_count = seqlen // w - 1\n",
    "\n",
    "    # group bsz and num_heads dimensions into one, then chunk seqlen into chunks of size w * 2\n",
    "    q = q.transpose(1, 2).reshape(bsz * num_heads, seqlen, head_dim)\n",
    "    k = k.transpose(1, 2).reshape(bsz * num_heads, seqlen, head_dim)\n",
    "\n",
    "    chunk_q = _chunk(q, w)\n",
    "    chunk_k = _chunk(k, w)\n",
    "\n",
    "    # matrix multipication\n",
    "    # bcxd: bsz*num_heads x chunks x 2w x head_dim\n",
    "    # bcyd: bsz*num_heads x chunks x 2w x head_dim\n",
    "    # bcxy: bsz*num_heads x chunks x 2w x 2w\n",
    "    chunk_attn = torch.einsum('bcxd,bcyd->bcxy', (chunk_q, chunk_k))  # multiply\n",
    "\n",
    "    # convert diagonals into columns\n",
    "    diagonal_chunk_attn = _skew(chunk_attn, direction=(0, 0, 0, 1), padding_value=padding_value)\n",
    "\n",
    "    # allocate space for the overall attention matrix where the chunks are compined. The last dimension\n",
    "    # has (w * 2 + 1) columns. The first (w) columns are the w lower triangles (attention from a word to\n",
    "    # w previous words). The following column is attention score from each word to itself, then\n",
    "    # followed by w columns for the upper triangle.\n",
    "\n",
    "    diagonal_attn = diagonal_chunk_attn.new_empty((bsz * num_heads, chunks_count + 1, w, w * 2 + 1))\n",
    "\n",
    "    # copy parts from diagonal_chunk_attn into the compined matrix of attentions\n",
    "    # - copying the main diagonal and the upper triangle\n",
    "    diagonal_attn[:, :-1, :, w:] = diagonal_chunk_attn[:, :, :w, :w + 1]\n",
    "    diagonal_attn[:, -1, :, w:] = diagonal_chunk_attn[:, -1, w:, :w + 1]\n",
    "    # - copying the lower triangle\n",
    "    diagonal_attn[:, 1:, :, :w] = diagonal_chunk_attn[:, :, - (w + 1):-1, w + 1:]\n",
    "    diagonal_attn[:, 0, 1:w, 1:w] = diagonal_chunk_attn[:, 0, :w - 1, 1 - w:]\n",
    "\n",
    "    # separate bsz and num_heads dimensions again\n",
    "    diagonal_attn = diagonal_attn.view(bsz, num_heads, seqlen, 2 * w + 1).transpose(2, 1)\n",
    "\n",
    "    mask_invalid_locations(diagonal_attn, w, 1, False)\n",
    "    return diagonal_attn\n",
    "\n",
    "\n",
    "def sliding_chunks_matmul_pv(prob: torch.Tensor, v: torch.Tensor, w: int):\n",
    "    '''Same as sliding_chunks_matmul_qk but for prob and value tensors. It is expecting the same output\n",
    "    format from sliding_chunks_matmul_qk'''\n",
    "    bsz, seqlen, num_heads, head_dim = v.size()\n",
    "    assert seqlen % (w * 2) == 0\n",
    "    assert prob.size()[:3] == v.size()[:3]\n",
    "    assert prob.size(3) == 2 * w + 1\n",
    "    chunks_count = seqlen // w - 1\n",
    "    # group bsz and num_heads dimensions into one, then chunk seqlen into chunks of size 2w\n",
    "    chunk_prob = prob.transpose(1, 2).reshape(bsz * num_heads, seqlen // w, w, 2 * w + 1)\n",
    "\n",
    "    # group bsz and num_heads dimensions into one\n",
    "    v = v.transpose(1, 2).reshape(bsz * num_heads, seqlen, head_dim)\n",
    "\n",
    "    # pad seqlen with w at the beginning of the sequence and another w at the end\n",
    "    padded_v = F.pad(v, (0, 0, w, w), value=-1)\n",
    "\n",
    "    # chunk padded_v into chunks of size 3w and an overlap of size w\n",
    "    chunk_v_size = (bsz * num_heads, chunks_count + 1, 3 * w, head_dim)\n",
    "    chunk_v_stride = padded_v.stride()\n",
    "    chunk_v_stride = chunk_v_stride[0], w * chunk_v_stride[1], chunk_v_stride[1], chunk_v_stride[2]\n",
    "    chunk_v = padded_v.as_strided(size=chunk_v_size, stride=chunk_v_stride)\n",
    "\n",
    "    skewed_prob = _skew2(chunk_prob, padding_value=0)\n",
    "\n",
    "    context = torch.einsum('bcwd,bcdh->bcwh', (skewed_prob, chunk_v))\n",
    "    return context.view(bsz, num_heads, seqlen, head_dim).transpose(1, 2)\n",
    "\n",
    "\n",
    "def pad_to_window_size(input_ids: torch.Tensor,\n",
    "                       one_sided_window_size: int, pad_token_id: int):\n",
    "    '''A helper function to pad tokens and mask to work with the sliding_chunks implementation of Longformer selfattention.\n",
    "    Input:\n",
    "        input_ids = torch.Tensor(bsz x seqlen): ids of wordpieces\n",
    "        attention_mask = torch.Tensor(bsz x seqlen): attention mask\n",
    "        one_sided_window_size = int: window size on one side of each token\n",
    "        pad_token_id = int: tokenizer.pad_token_id\n",
    "    Returns\n",
    "        (input_ids, attention_mask) padded to length divisible by 2 * one_sided_window_size\n",
    "    '''\n",
    "    w = int(2 * one_sided_window_size)\n",
    "    seqlen = input_ids.size(1)\n",
    "    padding_len = (w - seqlen % w) % w\n",
    "    input_ids = F.pad(input_ids, (0, 0, 0, 0, 0, padding_len), value=pad_token_id)\n",
    "    return input_ids\n",
    "\n",
    "def _get_invalid_locations_mask_fixed_dilation(seq_len: int, w: int, d: int):\n",
    "    diagonals_list = []\n",
    "    for j in range(-d * w, d, d):\n",
    "        diagonal_mask = torch.zeros(seq_len, device='cpu', dtype=torch.uint8)\n",
    "        diagonal_mask[:-j] = 1\n",
    "        diagonals_list.append(diagonal_mask)\n",
    "    return torch.stack(diagonals_list, dim=-1)\n",
    "\n",
    "@lru_cache()\n",
    "def _get_invalid_locations_mask(w: int, d: Union[torch.Tensor,int], autoregressive: bool, device: str):\n",
    "    if isinstance(d, int):\n",
    "        affected_seq_len = w * d\n",
    "        mask = _get_invalid_locations_mask_fixed_dilation(affected_seq_len, w, d)\n",
    "        mask = mask[None, :, None, :]\n",
    "    else:\n",
    "        affected_seq_len = w * d.max()\n",
    "        head_masks = []\n",
    "        d_list = d.cpu().numpy().tolist()\n",
    "        for d in d_list:\n",
    "            one_head_mask = _get_invalid_locations_mask_fixed_dilation(affected_seq_len, w, d)\n",
    "            head_masks.append(one_head_mask)\n",
    "        mask = torch.stack(head_masks, dim=-2)\n",
    "        mask = mask[None, :, :, :]\n",
    "\n",
    "    ending_mask = None if autoregressive else mask.flip(dims=(1, 3)).bool().to(device)\n",
    "    return affected_seq_len, mask.bool().to(device), ending_mask\n",
    "\n",
    "def mask_invalid_locations(input_tensor: torch.Tensor, w: int, d: Union[torch.Tensor, int], autoregressive: bool) -> torch.Tensor:\n",
    "    affected_seq_len, beginning_mask, ending_mask = _get_invalid_locations_mask(w, d, autoregressive, input_tensor.device)\n",
    "    seq_len = input_tensor.size(1)\n",
    "    beginning_input = input_tensor[:, :affected_seq_len, :, :w+1]\n",
    "    beginning_mask = beginning_mask[:, :seq_len].expand(beginning_input.size())\n",
    "    beginning_input.masked_fill_(beginning_mask, -float('inf'))\n",
    "    if not autoregressive:\n",
    "        ending_input = input_tensor[:, -affected_seq_len:, :, -(w+1):]\n",
    "        ending_mask = ending_mask[:, -seq_len:].expand(ending_input.size())\n",
    "        ending_input.masked_fill_(ending_mask, -float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_0S2GCdNbXM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "def torch_bmm_nd(inp_1, inp_2, ndim):\n",
    "    \"\"\"Fast nd matrix multiplication\"\"\"\n",
    "    # faster replacement of torch.einsum (\"bhqk,bhkd->bhqd\")\n",
    "    return torch.bmm(\n",
    "        inp_1.reshape((-1,) + inp_1.shape[-2:]), inp_2.reshape((-1,) + inp_2.shape[-2:])\n",
    "    ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 1]))\n",
    "\n",
    "\n",
    "def torch_bmm_nd_transpose(inp_1, inp_2, ndim):\n",
    "    \"\"\"Fast nd matrix multiplication with transpose\"\"\"\n",
    "    # faster replacement of torch.einsum (bhqd,bhkd->bhqk)\n",
    "    return torch.bmm(\n",
    "        inp_1.reshape((-1,) + inp_1.shape[-2:]),\n",
    "        inp_2.reshape((-1,) + inp_2.shape[-2:]).transpose(1, 2),\n",
    "    ).view(inp_1.shape[: ndim - 2] + (inp_1.shape[ndim - 2], inp_2.shape[ndim - 2]))\n",
    "\n",
    "\n",
    "def create_band_mask(attention_mask: torch.Tensor, block_size: int):\n",
    "    batch_size, seq_length = attention_mask.size()\n",
    "    if seq_length % block_size != 0:\n",
    "        raise ValueError(\n",
    "            f\"Sequence length must be multiple of block size, but sequence length is {seq_length}, while block\"\n",
    "            f\" size is {block_size}.\"\n",
    "        )\n",
    "\n",
    "    def create_band_mask_from_inputs(from_blocked_mask, to_blocked_mask):\n",
    "        \"\"\"\n",
    "        Create 3D attention mask from a 2D tensor mask.\n",
    "\n",
    "        Args:\n",
    "            from_blocked_mask: 2D Tensor of shape [batch_size,\n",
    "            from_seq_length//from_block_size, from_block_size].\n",
    "            to_blocked_mask: int32 Tensor of shape [batch_size,\n",
    "            to_seq_length//to_block_size, to_block_size].\n",
    "\n",
    "        Returns:\n",
    "            float Tensor of shape [batch_size, 1, from_seq_length//from_block_size-4, from_block_size,\n",
    "            3*to_block_size].\n",
    "        \"\"\"\n",
    "        exp_blocked_to_pad = torch.cat(\n",
    "            [\n",
    "                to_blocked_mask[:, 1:-3],\n",
    "                to_blocked_mask[:, 2:-2],\n",
    "                to_blocked_mask[:, 3:-1],\n",
    "            ],\n",
    "            dim=2,\n",
    "        )\n",
    "        band_mask = torch.einsum(\n",
    "            \"blq,blk->blqk\", from_blocked_mask[:, 2:-2], exp_blocked_to_pad\n",
    "        )\n",
    "        band_mask.unsqueeze_(1)\n",
    "        return band_mask\n",
    "\n",
    "    blocked_encoder_mask = attention_mask.view(\n",
    "        batch_size, seq_length // block_size, block_size\n",
    "    )\n",
    "    band_mask = create_band_mask_from_inputs(blocked_encoder_mask, blocked_encoder_mask)\n",
    "\n",
    "    return band_mask\n",
    "\n",
    "\n",
    "def big_bird(\n",
    "    query_layer,\n",
    "    key_layer,\n",
    "    value_layer,\n",
    "    block_size,\n",
    "):\n",
    "    attn_mask_penalty = -10000.0\n",
    "    bsz = query_layer.shape[0]\n",
    "    n_heads = query_layer.shape[1]\n",
    "    seq_len = query_layer.shape[2]\n",
    "    attention_mask = torch.ones(\n",
    "        (bsz, seq_len), device=query_layer.device, dtype=query_layer.dtype\n",
    "    )\n",
    "    band_mask = create_band_mask(\n",
    "        attention_mask,\n",
    "        block_size,\n",
    "    )\n",
    "    to_mask = attention_mask.view(bsz, 1, 1, seq_len)\n",
    "\n",
    "    blocked_query_matrix = query_layer.view(\n",
    "        bsz, n_heads, seq_len // block_size, block_size, -1\n",
    "    )\n",
    "    blocked_key_matrix = key_layer.view(\n",
    "        bsz, n_heads, seq_len // block_size, block_size, -1\n",
    "    )\n",
    "    blocked_value_matrix = value_layer.view(\n",
    "        bsz, n_heads, seq_len // block_size, block_size, -1\n",
    "    )\n",
    "    exp_blocked_key_matrix = torch.cat(\n",
    "        [\n",
    "            blocked_key_matrix[:, :, 1:-3],\n",
    "            blocked_key_matrix[:, :, 2:-2],\n",
    "            blocked_key_matrix[:, :, 3:-1],\n",
    "        ],\n",
    "        dim=3,\n",
    "    )  # [bsz, n_heads, seq_len//block_size-4, 3*block_size, -1]\n",
    "    exp_blocked_value_matrix = torch.cat(\n",
    "        [\n",
    "            blocked_value_matrix[:, :, 1:-3],\n",
    "            blocked_value_matrix[:, :, 2:-2],\n",
    "            blocked_value_matrix[:, :, 3:-1],\n",
    "        ],\n",
    "        dim=3,\n",
    "    )  # [bsz, n_heads, seq_len//block_size-4, 3*block_size, -1]\n",
    "    middle_query_matrix = blocked_query_matrix[:, :, 2:-2]\n",
    "\n",
    "    # sliding attention scores for q[-2:2]\n",
    "    # [bsz, n_heads, seq_len//block_size-4, block_size, -1] x [b, n_heads, seq_len//block_size-4, 3*block_size, -1]\n",
    "    inner_band_product = torch_bmm_nd_transpose(\n",
    "        middle_query_matrix, exp_blocked_key_matrix, ndim=5\n",
    "    )\n",
    "    #     ==> [bsz, n_heads, seq_len//block_size-4, block_size, 3*block_size]\n",
    "\n",
    "    # randn attention scores for q[-2:2]\n",
    "    # [bsz, n_heads, seq_len//block_size-4, block_size, -1] x [bsz, n_heads, seq_len//block_size-4, n_rand_blocks*block_size, -1]\n",
    "    #     ==> [bsz, n_heads, seq_len//block_size-4, block_size, n_rand_blocks*block_size]\n",
    "\n",
    "    # Including 1st block (since it's global)\n",
    "    first_band_product = torch.einsum(\n",
    "        \"bhlqd,bhkd->bhlqk\", middle_query_matrix, blocked_key_matrix[:, :, 0]\n",
    "    )  # [bsz, n_heads, seq_len//block_size-4, block_size, -1] x [bsz, n_heads, block_size, -1] ==> [bsz, n_heads, seq_len//block_size-4, block_size, block_size]\n",
    "\n",
    "    # Including last block (since it's global)\n",
    "    last_band_product = torch.einsum(\n",
    "        \"bhlqd,bhkd->bhlqk\", middle_query_matrix, blocked_key_matrix[:, :, -1]\n",
    "    )  # [bsz, n_heads, seq_len//block_size-4, block_size, -1] x [bsz, n_heads, block_size, -1] ==> [bsz, n_heads, seq_len//block_size-4, block_size, block_size]\n",
    "\n",
    "    # masking padded tokens\n",
    "    inner_band_product += (1.0 - band_mask) * attn_mask_penalty\n",
    "    first_band_product += (\n",
    "        1.0 - to_mask[:, :, :, :block_size].unsqueeze(3)\n",
    "    ) * attn_mask_penalty\n",
    "    last_band_product += (\n",
    "        1.0 - to_mask[:, :, :, -block_size:].unsqueeze(3)\n",
    "    ) * attn_mask_penalty\n",
    "\n",
    "    # completing attention scores matrix for all q[-2:2]\n",
    "    band_product = torch.cat(\n",
    "        [first_band_product, inner_band_product, last_band_product],\n",
    "        dim=-1,\n",
    "    )  # [bsz, n_heads, seq_len//block_size-4, block_size, (5+n_rand_blocks)*block_size]\n",
    "\n",
    "    # safely doing softmax since attention matrix is completed\n",
    "    attn_weights = nn.functional.softmax(\n",
    "        band_product, dim=-1\n",
    "    )  # [bsz, n_heads, seq_len//block_size-4, block_size, (5+n_rand_blocks)*block_size]\n",
    "\n",
    "    # contribution of sliding keys\n",
    "    # [bsz, n_heads, m//block_size-4, block_size, 3*block_size] x [bsz, n_heads, seq_len//block_size-4, 3*block_size, -1]\n",
    "    context_layer = torch_bmm_nd(\n",
    "        attn_weights[:, :, :, :, block_size : 4 * block_size],\n",
    "        exp_blocked_value_matrix,\n",
    "        ndim=5,\n",
    "    )\n",
    "    #     ==> [bsz, n_heads, seq_len//block_size-4, block_size, -1]\n",
    "\n",
    "    return context_layer\n",
    "\n",
    "def pad_to_block_size(input_ids: torch.Tensor,\n",
    "                       one_sided_window_size: int, pad_token_id: int):\n",
    "    '''A helper function to pad tokens and mask to work with the sliding_chunks implementation of Longformer selfattention.\n",
    "    Input:\n",
    "        input_ids = torch.Tensor(bsz x seqlen): ids of wordpieces\n",
    "        attention_mask = torch.Tensor(bsz x seqlen): attention mask\n",
    "        one_sided_window_size = int: window size on one side of each token\n",
    "        pad_token_id = int: tokenizer.pad_token_id\n",
    "    Returns\n",
    "        (input_ids, attention_mask) padded to length divisible by 2 * one_sided_window_size\n",
    "    '''\n",
    "    block_size = math.ceil(window_size / 3)\n",
    "    seqlen = input_ids.size(2)\n",
    "    padding_len = (block_size - seqlen % block_size) % block_size\n",
    "    input_ids = F.pad(input_ids, (0, 0, 0, padding_len), value=pad_token_id)\n",
    "    return input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnyCiC_QIiDN"
   },
   "outputs": [],
   "source": [
    "def full_attention_kernel(query, key, value, window_size):\n",
    "    att = torch.matmul(query, key.transpose(-1, -2))\n",
    "    return torch.matmul(att, value)\n",
    "\n",
    "def longformer_tvm_kernel(query, key, value, window_size):\n",
    "    att = longformer_tvm_matmul(query, key, window_size, 1, False)\n",
    "    return longformer_tvm_matmul(att, value, window_size, 1, True)\n",
    "\n",
    "def longformer_pytorch_kernel(query, key, value, window_size):\n",
    "    query = pad_to_window_size(query, window_size, 0)\n",
    "    key = pad_to_window_size(key, window_size, 0)\n",
    "    value = pad_to_window_size(value, window_size, 0)\n",
    "    att = sliding_chunks_matmul_qk(query, key, window_size, 0)\n",
    "    return sliding_chunks_matmul_pv(att, value, window_size)\n",
    "\n",
    "def big_bird_kernel(query, key, value, window_size):\n",
    "    query = pad_to_block_size(query, window_size, 0)\n",
    "    key = pad_to_block_size(key, window_size, 0)\n",
    "    value = pad_to_block_size(value, window_size, 0)\n",
    "    return big_bird(query, key, value, math.ceil(window_size / 3))\n",
    "\n",
    "def custom_kernel(query, key, value, window_size):\n",
    "    att = window_matmul.window_matmul(query, key, window_size)\n",
    "    return window_matmul.unwindow_matmul(att, value, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 1132098,
     "status": "ok",
     "timestamp": 1685699815839,
     "user": {
      "displayName": "Ferdinand Schlatt",
      "userId": "05646477749655616958"
     },
     "user_tz": -120
    },
    "id": "mYJkMjJmHOgm",
    "outputId": "6545d488-9b21-46dc-d756-82bb891dba28"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_heads = 12\n",
    "hidden_dim = 384\n",
    "seq_lens = list(2**idx for idx in range(6, 13))\n",
    "repeat = 25\n",
    "settings = {\n",
    "    \"Full Attention\": {\"func\": full_attention_kernel, \"window_sizes\": [None]},\n",
    "    \"Longformer (TVM)\": {\"func\": longformer_tvm_kernel, \"window_sizes\": [4, 64]},\n",
    "    \"Longformer (PT)\": {\"func\": longformer_pytorch_kernel, \"window_sizes\": [4, 64]},\n",
    "    \"BigBird\": {\"func\": big_bird_kernel, \"window_sizes\": [4, 64]},\n",
    "    \"Ours\": {\"func\": custom_kernel, \"window_sizes\": [4, 64]},\n",
    "}\n",
    "kernel_data = []\n",
    "# with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "for seq_len in tqdm.tqdm(seq_lens):\n",
    "    shape = (batch_size, num_heads, seq_len, hidden_dim // num_heads)\n",
    "    for name, implementation_settings in settings.items():\n",
    "        query = torch.rand(*shape, device=device)\n",
    "        key = torch.rand(*shape, device=device)\n",
    "        value = torch.rand(*shape, device=device)\n",
    "        if \"Longformer\" in name:\n",
    "            query = query.transpose(-2, -3).contiguous()\n",
    "            key = key.transpose(-2, -3).contiguous()\n",
    "            value = value.transpose(-2, -3).contiguous()\n",
    "        run_times = []\n",
    "        window_sizes = implementation_settings[\"window_sizes\"]\n",
    "        func = implementation_settings[\"func\"]\n",
    "        for window_size in window_sizes:\n",
    "            run_times = []\n",
    "            for _ in range(repeat):\n",
    "                try:\n",
    "                    begin_mem = torch.cuda.memory_allocated()\n",
    "                    torch.cuda.reset_peak_memory_stats()\n",
    "                    start = time.perf_counter()\n",
    "                    func(query, key, value, window_size)\n",
    "                    torch.cuda.synchronize()\n",
    "                    run_time = time.perf_counter() - start\n",
    "                    max_mem = torch.cuda.max_memory_allocated() - begin_mem\n",
    "                    # time.sleep(0.001)\n",
    "                    save_name = name\n",
    "                    kernel_data.append([seq_len, name, window_size, run_time, max_mem])\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                    # print(name, window_size, e)\n",
    "kernel_df = pd.DataFrame(kernel_data, columns=[\"seq_len\", \"name\", \"window_size\", \"time\", \"space\"])\n",
    "kernel_df.to_json(\"kernel_df.json\")\n",
    "del kernel_data\n",
    "kernel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "executionInfo": {
     "elapsed": 2817,
     "status": "ok",
     "timestamp": 1685779481146,
     "user": {
      "displayName": "Ferdinand Schlatt",
      "userId": "05646477749655616958"
     },
     "user_tz": -120
    },
    "id": "uii5v5edr9Z8",
    "outputId": "2ba4cec0-4fac-4708-e146-772166754eae"
   },
   "outputs": [],
   "source": [
    "plot_df = kernel_df.copy()\n",
    "plot_df[\"time\"] = plot_df[\"time\"] / batch_size * 1000\n",
    "plot_df[\"space\"] = plot_df[\"space\"] / batch_size\n",
    "_, unit = human_readable_bytes(plot_df[\"space\"])\n",
    "plot_df[\"space\"] = human_readable_bytes(plot_df[\"space\"], unit)[0]\n",
    "plot_df = plot_df.loc[~plot_df[\"window_size\"].isin([0, 1])]\n",
    "plot_df[\"window_size\"] = plot_df[\"window_size\"].fillna(float(\"inf\"))\n",
    "plot_df = plot_df.groupby([\"name\", \"window_size\", \"seq_len\"], dropna=False).median()\n",
    "plot_df = plot_df.reindex([\"Full Attention\", \"BigBird\", \"Longformer (PT)\", \"Longformer (TVM)\", \"Ours\"], level=0)\n",
    "# plot_df\n",
    "\n",
    "scale = 0.85\n",
    "fig, axes = plt.subplots(2, 2, figsize=(6 * scale, 5 * scale), sharex=True, sharey=\"row\")\n",
    "labels = set()\n",
    "colors = {}\n",
    "for approach_idx, approach in enumerate(plot_df.index.get_level_values('name').unique()):\n",
    "    approach_df = plot_df.loc[approach]\n",
    "    window_sizes = sorted(approach_df.index.get_level_values(\"window_size\").unique())\n",
    "    if len(window_sizes) == 1:\n",
    "        window_sizes = [window_sizes[0]] * 2\n",
    "    for row_idx in range(2):\n",
    "        for col_idx, window_size in enumerate(window_sizes):\n",
    "            value_median = approach_df.loc[window_size]\n",
    "            ax = axes[row_idx, col_idx]\n",
    "\n",
    "            x = value_median.index.values\n",
    "            if row_idx == 0:\n",
    "                y = value_median.loc[:, \"time\"]\n",
    "            else:\n",
    "                y = value_median.loc[:, \"space\"]\n",
    "            \n",
    "            label = None\n",
    "            if row_idx == 0 and col_idx == 0:\n",
    "                label = approach\n",
    "            line = ax.plot(x, y, label=label if col_idx == 0 else None, marker=markers[approach_idx])\n",
    "\n",
    "axes[0, 0].set_xscale(\"log\", base=2)\n",
    "axes[0, 0].set_yscale(\"log\")\n",
    "axes[1, 0].set_yscale(\"log\")\n",
    "axes[0, 0].get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "axes[0, 0].minorticks_off()\n",
    "axes[0, 0].set_xticks(seq_lens[::2])\n",
    "axes[0, 0].set_title(\"Window Size 4\")\n",
    "axes[0, 0].set_ylabel(\"ms / Sequence\")\n",
    "axes[0, 1].set_title(\"Window Size 64\")\n",
    "axes[1, 0].set_ylabel(f\"{unit} / Sequence\")\n",
    "axes[1, 0].set_xlabel(\"Sequence Length\")\n",
    "axes[1, 1].set_xlabel(\"Sequence Length\")\n",
    "# axes[0, 0].set_ylim(None, 1.5)\n",
    "# axes[1, 0].set_ylim(None, 1000)\n",
    "fig.legend(ncols=3, bbox_to_anchor=(0.5, -0.025), loc=\"center\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"kernel-efficiency.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from listformer.model.listformer import (\n",
    "    list_softmax,\n",
    "    untranspose_for_scores,\n",
    "    to_windowed_attention_mask\n",
    ")\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "def pad_to_window_size_and_transpose(\n",
    "    tensor: torch.Tensor, one_sided_window_size: int, pad_token_id: int\n",
    "):\n",
    "    batch_size, num_heads, num_docs, seq_len, head_dim = tensor.shape\n",
    "    tensor = tensor.permute(0, 2, 3, 1, 4)\n",
    "    tensor = tensor.view(batch_size * num_docs, seq_len, num_heads, head_dim)\n",
    "    w = int(2 * one_sided_window_size)\n",
    "    padding_len = (w - seq_len % w) % w\n",
    "    tensor = F.pad(tensor, (0, 0, 0, 0, 0, padding_len), value=pad_token_id)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def unpad_and_transpose(\n",
    "    tensor: torch.Tensor, batch_size, num_heads, num_docs, seq_len, head_dim\n",
    "):\n",
    "    return tensor.view(batch_size, num_docs, -1, num_heads, head_dim).permute(\n",
    "        0, 3, 1, 2, 4\n",
    "    )[:, :, :, :seq_len, :]\n",
    "\n",
    "\n",
    "def _forward(\n",
    "    self,\n",
    "    inp,\n",
    "    attention_window_sizes,\n",
    ") -> torch.Tensor:\n",
    "    # TODO use nested tensors when broadcasting is supported\n",
    "    # https://pytorch.org/docs/stable/nested.html\n",
    "    query_layer = inp.query_layer\n",
    "    key_layers = inp.key_layers\n",
    "    value_layers = inp.value_layers\n",
    "    attention_masks = inp.attention_masks\n",
    "\n",
    "    batch_size, num_heads, num_docs, seq_len, head_dim = query_layer.shape\n",
    "\n",
    "    # Take the dot product between \"query\" and \"key\" to get the raw attention scores\n",
    "    attention_scores = []\n",
    "    for key_layer, window_size in zip(key_layers, attention_window_sizes):\n",
    "        if window_size is not None:\n",
    "            attention_score = sliding_chunks_matmul_qk(\n",
    "                pad_to_window_size_and_transpose(query_layer, window_size, 0),\n",
    "                pad_to_window_size_and_transpose(key_layer, window_size, 0),\n",
    "                window_size,\n",
    "                0,\n",
    "            )\n",
    "            attention_score = unpad_and_transpose(\n",
    "                attention_score,\n",
    "                batch_size,\n",
    "                num_heads,\n",
    "                num_docs,\n",
    "                seq_len,\n",
    "                attention_score.shape[-1],\n",
    "            )\n",
    "            attention_scores.append(attention_score)\n",
    "        else:\n",
    "            attention_scores.append(\n",
    "                torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "            )\n",
    "    # attention: batch_size x num_heads x num_docs x seq_len\n",
    "    # or\n",
    "    # attention: batch_size x num_heads x num_docs * seq_len x num_docs * seq_len\n",
    "\n",
    "    attention_scores = [\n",
    "        attention_score / math.sqrt(self.attention_head_size)\n",
    "        for attention_score in attention_scores\n",
    "    ]\n",
    "\n",
    "    iterator = enumerate(zip(attention_masks, attention_scores, attention_window_sizes))\n",
    "    for idx, (attention_mask, attention_score, attention_window_size) in iterator:\n",
    "        if attention_mask is not None:\n",
    "            if attention_window_size is not None:\n",
    "                attention_mask = to_windowed_attention_mask(\n",
    "                    attention_mask, attention_window_size\n",
    "                )\n",
    "            attention_score = attention_score + attention_mask\n",
    "        attention_score = attention_score.clamp(torch.finfo(attention_score.dtype).min)\n",
    "        attention_scores[idx] = attention_score\n",
    "\n",
    "    # Normalize the attention scores to probabilities\n",
    "    attention_probs = list_softmax(attention_scores, dim=-1)\n",
    "\n",
    "    # This is actually dropping out entire tokens to attend to, which might\n",
    "    # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "    attention_probs = [\n",
    "        self.dropout(attention_prob) for attention_prob in attention_probs\n",
    "    ]\n",
    "\n",
    "    context_layers = []\n",
    "    iterator = zip(attention_probs, value_layers, attention_window_sizes)\n",
    "    for attention_prob, value_layer, window_size in iterator:\n",
    "        attention_prob = attention_prob.to(value_layer)\n",
    "        if window_size is not None:\n",
    "            context_layer = sliding_chunks_matmul_pv(\n",
    "                pad_to_window_size_and_transpose(attention_prob, window_size, 0),\n",
    "                pad_to_window_size_and_transpose(value_layer, window_size, 0),\n",
    "                window_size,\n",
    "            )\n",
    "            context_layer = unpad_and_transpose(\n",
    "                context_layer, batch_size, num_heads, num_docs, seq_len, head_dim\n",
    "            )\n",
    "            context_layers.append(context_layer)\n",
    "        else:\n",
    "            context_layers.append(torch.matmul(attention_prob, value_layer))\n",
    "\n",
    "    context_layer = reduce(torch.add, context_layers)\n",
    "\n",
    "    context_layer = untranspose_for_scores(context_layer, self.all_head_size)\n",
    "\n",
    "    return context_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "1da9705e393545598647f51a8ebf2048",
      "1154f25e1b434f998fa414ae1ae17976",
      "47c2890178ad4561a0462b0069447ac8",
      "39c9d17d191848239cadd2257a0dee30",
      "1a19cbf33bb942548d16b3ae824bb636",
      "10e99217fdda4c2d9029f571256e65d9",
      "c305b01ab68f421882cfb05e31b966d2",
      "af349d82dc1d455badd7891cca8998f5",
      "e119bd9d8a94423db996396ec2d15cd5",
      "53d4a79e6ed44b868182d2c65812dd54",
      "6df2b4addd4644e38a27821acbe28b5e",
      "ddec98ca031d4ed0bdba0e367766d31f",
      "6fa3668da1644401a4294fd2d27911cd",
      "f442d06fdd0a4446b841aebce9e00d94",
      "86b9271859614ca79cd3740ecbbe3eac",
      "30fe3d812b814765840be83290d8338c",
      "62a99d84a440457784e63c5221c291da",
      "5ba211e7bdd14afab25ba1662271fe6a",
      "da13db9e57ad41929ea0beee0bb030c0",
      "0c3c140249634e9bade635345ad90513",
      "5ec92227d4d44df7a189e49624abbc75",
      "bd8c05d409b74a59a3fea92f7b46ff00",
      "f52dcbfed6354ae19f4560061eab371a",
      "f18f688ec61e4b99bcf0f4b530fdbe18",
      "3ec6d72acf56456ea1517cc41a8cab4d",
      "027aeab48d9a403387130a3de585d81b",
      "0e197aa9568e47fda1148735bc655f45",
      "f95ff4c899ea40a7ba17a85e0c1a0008",
      "b7892e3b15a448328ccce8e6e05f3951",
      "0f98702e17804fc2b03461b24548ed40",
      "21c99b682cdc4ce89528b45023247c33",
      "908c49b2fa9c4621869f2fd1659b0f28",
      "79d0781832824cae9f5ca07b4e1885b6"
     ]
    },
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1685772485739,
     "user": {
      "displayName": "Ferdinand Schlatt",
      "userId": "05646477749655616958"
     },
     "user_tz": -120
    },
    "id": "92nqkWkeRQiJ",
    "outputId": "10b129b5-6f68-4500-bd16-c2542b6e1d52"
   },
   "outputs": [],
   "source": [
    "max_emb = 4672\n",
    "config = transformers.AutoConfig.from_pretrained(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "config.update({\"max_position_embeddings\": max_emb})\n",
    "longformer_config = transformers.AutoConfig.from_pretrained(\n",
    "    \"allenai/longformer-base-4096\"\n",
    ")\n",
    "longformer_config.update(config.to_dict())\n",
    "longformer_config.update({\"attention_window\": [128] * config.num_hidden_layers})\n",
    "bert_config = transformers.AutoConfig.from_pretrained(\"bert-base-uncased\")\n",
    "bert_config.update(config.to_dict())\n",
    "full_attention_config = ListformerConfig()\n",
    "full_attention_config.update(config.to_dict())\n",
    "full_attention_config.update({\"cls_token_id\": 1, \"max_position_embeddings\": 4672})\n",
    "sparse_cross_encoder_config = deepcopy(full_attention_config)\n",
    "sparse_cross_encoder_config.update({\"query_doc_attention\": False, \"query_cls_attention\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zMwGTGOVmN7"
   },
   "outputs": [],
   "source": [
    "bert = transformers.BertModel(bert_config).eval().to(device)\n",
    "longformer = transformers.LongformerModel(longformer_config).eval().to(device)\n",
    "full_attention = ListformerModel(full_attention_config).eval().to(device)\n",
    "sparse_cross_encoder = ListformerModel(sparse_cross_encoder_config).eval().to(device)\n",
    "longformer_kernel = ListformerModel(sparse_cross_encoder_config).eval().to(device)\n",
    "for module in longformer_kernel.modules():\n",
    "    if module._get_name() == \"ListformerSelfAttention\":\n",
    "        setattr(module, \"_forward\", partial(_forward, module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 3975283,
     "status": "ok",
     "timestamp": 1685777375187,
     "user": {
      "displayName": "Ferdinand Schlatt",
      "userId": "05646477749655616958"
     },
     "user_tz": -120
    },
    "id": "oddO0C3CVprv",
    "outputId": "5db3ebf2-b2b9-4cfa-af6d-01f692e4c5e6"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Full Attention\": bert,\n",
    "    \"Longformer\": longformer,\n",
    "    \"QDS-Transformer\": longformer,\n",
    "    \"Sparse Cross-Encoder (No Cross)\": full_attention,\n",
    "    \"Sparse Cross-Encoder (No Kernel)\": longformer_kernel,\n",
    "    \"Sparse Cross-Encoder (Ours)\": sparse_cross_encoder,\n",
    "}\n",
    "\n",
    "repeat = 5\n",
    "query_len = 10\n",
    "num_tokens_per_sentence = 30\n",
    "seq_lens = list(2**idx for idx in range(6, 13)) + [164]\n",
    "window_sizes = [4, 64]\n",
    "\n",
    "pg = tqdm.tqdm(models.items())\n",
    "\n",
    "def expand_tensor(key, tensor, num_docs, use_batch_dim):\n",
    "    if key in (\"input_ids\", \"global_attention_mask\"):\n",
    "        return tensor.expand(num_docs, -1).clone().contiguous()\n",
    "    if key == \"query_input_ids\":\n",
    "        if use_batch_dim:\n",
    "            return tensor.expand(num_docs, -1).clone().contiguous()\n",
    "        return tensor.contiguous()\n",
    "    if key == \"doc_input_ids\":\n",
    "        if use_batch_dim:\n",
    "            return tensor.expand(num_docs, -1, -1).clone().contiguous()\n",
    "        return tensor.expand(-1, num_docs, -1).clone().contiguous()\n",
    "    raise ValueError(f\"unknown key {key}\")\n",
    "\n",
    "def find_max_docs(model, kwargs, use_batch_dim):\n",
    "    num_docs = 100\n",
    "    while True:\n",
    "        inp = {key: expand_tensor(key, tensor, num_docs, use_batch_dim) for key, tensor in kwargs.items()}\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                model(**inp)\n",
    "            torch.cuda.synchronize()\n",
    "            return num_docs\n",
    "        except torch.cuda.OutOfMemoryError:\n",
    "            if num_docs == 100:\n",
    "                num_docs = 128\n",
    "            else:\n",
    "                num_docs = num_docs // 2\n",
    "            if not num_docs:\n",
    "                raise ValueError(\"unable to run model\")\n",
    "            \n",
    "\n",
    "model_data = []\n",
    "# with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "for model_name, model in pg:\n",
    "    for seq_len in seq_lens:\n",
    "        doc_len = seq_len - query_len\n",
    "        torch.manual_seed(42)\n",
    "        kwargs = {}\n",
    "        model_window_sizes = [None]\n",
    "        if isinstance(model, ListformerModel):\n",
    "            model_window_sizes = window_sizes\n",
    "            kwargs[\"query_input_ids\"] = torch.randint(1000, 10000, (1, query_len,)).to(device)\n",
    "            kwargs[\"doc_input_ids\"] = torch.randint(1000, 10000, (1, 1, doc_len)).to(device)\n",
    "        else:\n",
    "            sequence_input = torch.randint(1000, 10000, (1, seq_len)).to(device)\n",
    "            kwargs[\"input_ids\"] = sequence_input\n",
    "            if model_name in (\"Longformer\", \"QDS-Transformer\"):\n",
    "                global_attention_mask = torch.zeros_like(sequence_input).to(device)\n",
    "                global_attention_mask[:, :query_len] = 1\n",
    "                kwargs[\"global_attention_mask\"] = global_attention_mask\n",
    "                model_window_sizes = window_sizes\n",
    "            if model_name == \"QDS-Transformer\":\n",
    "                kwargs[\"global_attention_mask\"][:, query_len::num_tokens_per_sentence] = 1\n",
    "\n",
    "        use_batch_dim = \"No Cross\" in model_name\n",
    "\n",
    "        for window_size in model_window_sizes:\n",
    "            if window_size is not None:\n",
    "                if hasattr(model.config, \"attention_window_size\"):\n",
    "                    model.config.attention_window_size = window_size\n",
    "                if hasattr(model.config, \"attention_window\"):\n",
    "                    model.config.attention_window = [window_size * 2] * model.config.num_hidden_layers\n",
    "                    for layer in model.encoder.layer:\n",
    "                        assert hasattr(layer.attention.self, \"one_sided_attn_window_size\")\n",
    "                        layer.attention.self.one_sided_attn_window_size = window_size\n",
    "            \n",
    "            num_docs = find_max_docs(model, kwargs, use_batch_dim)\n",
    "            inp = {key: expand_tensor(key, tensor, num_docs, use_batch_dim) for key, tensor in kwargs.items()}\n",
    "            if isinstance(model, ListformerModel):\n",
    "                inp = {\"inp\": model.preprocess(**inp)}\n",
    "            \n",
    "            pg.set_description(f\"{model_name} {seq_len} {query_len} {window_size} {num_docs}\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for _ in range(repeat):\n",
    "                    begin_mem = torch.cuda.memory_allocated()\n",
    "                    torch.cuda.reset_peak_memory_stats()\n",
    "                    start = time.perf_counter()\n",
    "                    if isinstance(model, ListformerModel):\n",
    "                        model.encode(**inp)\n",
    "                    else:\n",
    "                        model(**inp)\n",
    "                    torch.cuda.synchronize()\n",
    "                    model_time = time.perf_counter() - start\n",
    "                    max_mem = torch.cuda.max_memory_allocated() - begin_mem\n",
    "                    # time.sleep(0.001)\n",
    "                    model_data.append([model_name, query_len, seq_len, window_size, model_time, max_mem, num_docs])\n",
    "model_df = pd.DataFrame(model_data, columns=[\"name\", \"query_len\", \"seq_len\", \"window_size\", \"time\", \"space\", \"num_docs\"])\n",
    "model_df.to_json(\"model_df.json\")\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_df = pd.read_json(\"model_df.json\")\n",
    "median_df[\"time\"] = median_df[\"time\"] / median_df[\"num_docs\"] * 1000\n",
    "median_df[\"space\"] = median_df[\"space\"] / median_df[\"num_docs\"]\n",
    "_, unit = human_readable_bytes(median_df.loc[median_df[\"name\"].str.contains(\"Ours\"), \"space\"])\n",
    "median_df[\"space\"] = human_readable_bytes(median_df[\"space\"], unit)[0]\n",
    "median_df = median_df.loc[~median_df[\"window_size\"].isin([0, 1])]\n",
    "median_df[\"window_size\"] = median_df[\"window_size\"].fillna(float(\"inf\"))\n",
    "median_df = median_df.groupby([\"name\", \"window_size\", \"seq_len\", \"query_len\"], dropna=False)[[\"time\", \"space\"]].median()\n",
    "median_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "executionInfo": {
     "elapsed": 5170,
     "status": "ok",
     "timestamp": 1685777998393,
     "user": {
      "displayName": "Ferdinand Schlatt",
      "userId": "05646477749655616958"
     },
     "user_tz": -120
    },
    "id": "nyQB-xbeX6NB",
    "outputId": "dba31cd9-5c01-4953-80d6-b93b8b771bc8"
   },
   "outputs": [],
   "source": [
    "plot_df = median_df.loc[[\"Full Attention\", \"Longformer\", \"QDS-Transformer\", \"Sparse Cross-Encoder (Ours)\"]]\n",
    "plot_df = plot_df.drop(164, level=2)\n",
    "plot_df\n",
    "\n",
    "scale = 0.85\n",
    "fig, axes = plt.subplots(2, 2, figsize=(6 * scale, 5 * scale), sharex=True, sharey=\"row\")\n",
    "labels = set()\n",
    "colors = {}\n",
    "for approach_idx, approach in enumerate(plot_df.index.get_level_values('name').unique()):\n",
    "    approach_df = plot_df.loc[approach].loc[pd.IndexSlice[:, :, 10]]\n",
    "    window_sizes = sorted(approach_df.index.get_level_values(\"window_size\").unique())\n",
    "    if len(window_sizes) == 1:\n",
    "        window_sizes = [window_sizes[0]] * 2\n",
    "    for row_idx in range(2):\n",
    "        for col_idx, window_size in enumerate(window_sizes):\n",
    "            value_median = approach_df.loc[window_size]\n",
    "            ax = axes[row_idx, col_idx]\n",
    "\n",
    "            x = value_median.index.values\n",
    "            if row_idx == 0:\n",
    "                y = value_median.loc[:, \"time\"]\n",
    "            else:\n",
    "                y = value_median.loc[:, \"space\"]\n",
    "            \n",
    "            label = None\n",
    "            if row_idx == 0 and col_idx == 0:\n",
    "                label = approach\n",
    "            line = ax.plot(x, y, label=label if col_idx == 0 else None, marker=markers[approach_idx])\n",
    "\n",
    "axes[0, 0].set_xscale(\"log\", base=2)\n",
    "axes[0, 0].set_yscale(\"log\")\n",
    "axes[1, 0].set_yscale(\"log\")\n",
    "axes[0, 0].get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "axes[0, 0].set_xticks(seq_lens[::2])\n",
    "axes[0, 0].minorticks_off()\n",
    "axes[0, 0].set_title(\"Window Size 4\")\n",
    "axes[0, 0].set_ylabel(\"ms / Sequence\")\n",
    "axes[0, 1].set_title(\"Window Size 64\")\n",
    "axes[1, 0].set_ylabel(f\"{unit} / Sequence\")\n",
    "axes[1, 0].set_xlabel(\"Sequence Length\")\n",
    "axes[1, 1].set_xlabel(\"Sequence Length\")\n",
    "# axes[0, 0].set_ylim(0, 20)\n",
    "# axes[1, 0].set_ylim(None, 250)\n",
    "# fig.legend(loc=\"center\", bbox_to_anchor=(1.15, 0.5))\n",
    "fig.legend(ncols=2, bbox_to_anchor=(0.5, -0.025), loc=\"center\")\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"model-efficiency.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Full Attention\", float(\"inf\")),\n",
    "    (\"Longformer\", 64),\n",
    "    (\"QDS-Transformer\", 64),\n",
    "    (\"Sparse Cross-Encoder (Ours)\", 64),\n",
    "    (\"Sparse Cross-Encoder (Ours)\", 4),\n",
    "    (\"Sparse Cross-Encoder (No Kernel)\", 4),\n",
    "    (\"Sparse Cross-Encoder (No Cross)\", 4),\n",
    "]\n",
    "comparison_models = [(\"Full Attention\", float(\"inf\"), 164), (\"Longformer\", 64, 4096)]\n",
    "\n",
    "entries = []\n",
    "for seq_len in (164, 4096):\n",
    "    for model in models:\n",
    "        entries.append((*model, seq_len))\n",
    "\n",
    "efficiency_df = median_df.copy()\n",
    "efficiency_df.loc[pd.IndexSlice[:, :, [164]], \"time\"] = efficiency_df.loc[pd.IndexSlice[:, :, [164]], \"time\"] * 1000\n",
    "# efficiency_df.loc[:, \"time\"] = efficiency_df.loc[:, \"time\"] * 1000\n",
    "model_df = efficiency_df.droplevel(-1).reindex(entries).round()\n",
    "comparison_df = efficiency_df.droplevel(-1).loc[comparison_models].droplevel([0, 1]).round()\n",
    "improvement_df = (model_df - comparison_df) / comparison_df\n",
    "improvement_df = improvement_df.sort_index()\n",
    "improvement_df = improvement_df.unstack([0, 1]).reorder_levels((1, 2, 0), axis=1).sort_index(axis=1, ascending=(True, False))\n",
    "improvement_df = improvement_df.multiply(100).round().astype(int)\n",
    "\n",
    "absolute_df = efficiency_df.droplevel(-1).reindex(entries).round().astype(int)\n",
    "absolute_df = absolute_df.sort_index()\n",
    "absolute_df = absolute_df.unstack([0, 1]).reorder_levels((1, 2, 0), axis=1).sort_index(axis=1, ascending=(True, False))\n",
    "absolute_df = absolute_df\n",
    "\n",
    "table = absolute_df.astype(str) + \" (\" + improvement_df.astype(str) + \")\"\n",
    "\n",
    "table = table.stack(-1).droplevel(0)\n",
    "\n",
    "table = table.reindex(models, axis=1)\n",
    "\n",
    "display(table)\n",
    "print(table.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement_df = median_df.loc[pd.IndexSlice[:, :, 512]].droplevel(-1)\n",
    "time_improvement = pd.DataFrame(\n",
    "    (improvement_df.loc[:, \"time\"].values[None, :] - improvement_df.loc[:, \"time\"].values[:, None]) / improvement_df.loc[:, \"time\"].values[None, :],\n",
    "    index=improvement_df.index,\n",
    "    columns=improvement_df.index,\n",
    ")\n",
    "space_improvement = pd.DataFrame(\n",
    "    (improvement_df.loc[:, \"space\"].values[None, :] - improvement_df.loc[:, \"space\"].values[:, None]) / improvement_df.loc[:, \"space\"].values[None, :],\n",
    "    index=improvement_df.index,\n",
    "    columns=improvement_df.index,\n",
    ")\n",
    "# display(time_improvement.multiply(100).round())\n",
    "# display(space_improvement.multiply(100).round())\n",
    "improvement = pd.concat(\n",
    "    [\n",
    "        time_improvement.loc[\"Sparse Cross-Encoder (Ours)\"].drop(\"Sparse Cross-Encoder (Ours)\", axis=1),\n",
    "        space_improvement.loc[\"Sparse Cross-Encoder (Ours)\"].drop(\"Sparse Cross-Encoder (Ours)\", axis=1)\n",
    "    ],\n",
    "    keys=[\"Time\", \"Space\"],\n",
    "    names=[\"values\"],\n",
    ")\n",
    "# improvement.rename({\"window_size\": \"from_window_size\"}, axis=1, level=1)\n",
    "improvement = improvement.unstack(level=0)\n",
    "improvement.multiply(100).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement_df = median_df.loc[pd.IndexSlice[:, :, 512]].droplevel(-1)\n",
    "time_improvement = pd.DataFrame(\n",
    "    (improvement_df.loc[:, \"time\"].values[None, :] - improvement_df.loc[:, \"time\"].values[:, None]) / improvement_df.loc[:, \"time\"].values[None, :],\n",
    "    index=improvement_df.index,\n",
    "    columns=improvement_df.index,\n",
    ")\n",
    "space_improvement = pd.DataFrame(\n",
    "    (improvement_df.loc[:, \"space\"].values[None, :] - improvement_df.loc[:, \"space\"].values[:, None]) / improvement_df.loc[:, \"space\"].values[None, :],\n",
    "    index=improvement_df.index,\n",
    "    columns=improvement_df.index,\n",
    ")\n",
    "# display(time_improvement.multiply(100).round())\n",
    "# display(space_improvement.multiply(100).round())\n",
    "improvement = pd.concat(\n",
    "    [\n",
    "        time_improvement.loc[\"Sparse Cross-Encoder (Ours)\"].drop(\"Sparse Cross-Encoder (Ours)\", axis=1),\n",
    "        space_improvement.loc[\"Sparse Cross-Encoder (Ours)\"].drop(\"Sparse Cross-Encoder (Ours)\", axis=1)\n",
    "    ],\n",
    "    keys=[\"Time\", \"Space\"],\n",
    "    names=[\"values\"],\n",
    ")\n",
    "# improvement.rename({\"window_size\": \"from_window_size\"}, axis=1, level=1)\n",
    "improvement = improvement.unstack(level=0)\n",
    "improvement.multiply(100).round().loc[:, [(\"Full Attention\", float(\"inf\"), \"Time\")]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(improvement.multiply(100).round().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "#     \"Full Attention\": bert,\n",
    "#     \"Longformer\": longformer,\n",
    "#     \"QDS-Transformer\": longformer,\n",
    "    \"Sparse Cross-Encoder (Ours)\": sparse_cross_encoder,\n",
    "}\n",
    "\n",
    "repeat = 1\n",
    "num_docs = 100\n",
    "start = 512\n",
    "end = 4608\n",
    "step = 1024\n",
    "# step = 2048\n",
    "seq_lens = list(range(start, end + step, step))\n",
    "# query_lens = [10, 20, 30]\n",
    "query_lens = [10]\n",
    "num_tokens_per_sentence = 30\n",
    "# window_sizes = [4, 16, 64]\n",
    "window_sizes = [4, 64]\n",
    "\n",
    "def expand_tensor(key, tensor, num_docs):\n",
    "    if key in (\"input_ids\", \"global_attention_mask\"):\n",
    "        return tensor.expand(num_docs, -1).clone()\n",
    "    if key == \"query_input_ids\":\n",
    "        return tensor\n",
    "    if key == \"doc_input_ids\":\n",
    "        return tensor.expand(-1, num_docs, -1).clone()\n",
    "    raise ValueError(f\"unknown key {key}\")\n",
    "    \n",
    "def old_find_max_docs(model, kwargs):\n",
    "    lower_bound = 0\n",
    "    upper_bound = 8192\n",
    "    prev_num_docs = float(\"inf\")\n",
    "    while True:\n",
    "        inp = {key: expand_tensor(key, tensor, upper_bound) for key, tensor in kwargs.items()}\n",
    "        step = (upper_bound - lower_bound) // 2\n",
    "        print(lower_bound, upper_bound, step)\n",
    "        try:\n",
    "            model(**inp)\n",
    "            torch.cuda.synchronize()\n",
    "            lower_bound += step\n",
    "        except torch.cuda.OutOfMemoryError as e:\n",
    "            print(e)\n",
    "            upper_bound -= step\n",
    "        if lower_bound + 1 == upper_bound:\n",
    "            return lower_bound\n",
    "    \n",
    "    inp = {key: expand_tensor(key, tensor, upper_bound) for key, tensor in kwargs.items()}\n",
    "    fails = False\n",
    "    try:\n",
    "        model(**inp)\n",
    "        torch.cuda.synchronize()\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        fails = True\n",
    "    assert fails\n",
    "    inp = {key: expand_tensor(key, tensor, lower_bound) for key, tensor in kwargs.items()}\n",
    "    fails = False\n",
    "    try:\n",
    "        model(**inp)\n",
    "        torch.cuda.synchronize()\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        fails = True\n",
    "    assert not fails\n",
    "    return lower_bound\n",
    "\n",
    "def find_max_docs(model, kwargs):\n",
    "    num_docs = 8192\n",
    "    while True:\n",
    "        inp = {key: expand_tensor(key, tensor, num_docs) for key, tensor in kwargs.items()}\n",
    "        try:\n",
    "            model(**inp)\n",
    "            torch.cuda.synchronize()\n",
    "            return num_docs\n",
    "        except:\n",
    "            torch.cuda.OutOfMemoryError\n",
    "            num_docs = num_docs // 2\n",
    "        \n",
    "\n",
    "tracker = EmissionsTracker(save_to_file=False, log_level=\"error\")\n",
    "model_data = []\n",
    "\n",
    "pg = tqdm.tqdm(models.items())\n",
    "# with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "for model_name, model in pg:\n",
    "    for query_len in query_lens:\n",
    "        for seq_len in seq_lens:\n",
    "            if seq_len > 4096:\n",
    "                break\n",
    "            doc_len = seq_len - query_len\n",
    "            torch.manual_seed(42)\n",
    "            sequence_input = torch.randint(1000, 10000, (1, seq_len)).to(\n",
    "                device\n",
    "            )\n",
    "            query_input = torch.randint(1000, 10000, (1, query_len,)).to(device)\n",
    "            doc_input = torch.randint(1000, 10000, (1, 1, doc_len)).to(device)\n",
    "            kwargs = {}\n",
    "            model_window_sizes = [None]\n",
    "            if model_name in (\"Longformer\", \"Full Attention\", \"QDS-Transformer\"):\n",
    "                kwargs[\"input_ids\"] = sequence_input\n",
    "                if model_name in (\"Longformer\", \"QDS-Transformer\"):\n",
    "                    global_attention_mask = torch.zeros_like(sequence_input).to(device)\n",
    "                    global_attention_mask[:, :query_len] = 1\n",
    "                    kwargs[\"global_attention_mask\"] = global_attention_mask\n",
    "                    model_window_sizes = window_sizes\n",
    "                if model_name == \"QDS-Transformer\":\n",
    "                    kwargs[\"global_attention_mask\"][:, query_len::num_tokens_per_sentence] = 1\n",
    "            else:\n",
    "                model_window_sizes = window_sizes\n",
    "                kwargs[\"query_input_ids\"] = query_input\n",
    "                kwargs[\"doc_input_ids\"] = doc_input[:, :, :-1]\n",
    "\n",
    "            for window_size in model_window_sizes:\n",
    "                pg.set_description(f\"{model_name} {seq_len} {query_len} {window_size}\")\n",
    "                if window_size is not None:\n",
    "                    if hasattr(model.config, \"attention_window_size\"):\n",
    "                        model.config.attention_window_size = window_size\n",
    "                    if hasattr(model.config, \"attention_window\"):\n",
    "                        model.config.attention_window = [window_size * 2] * model.config.num_hidden_layers\n",
    "                        for layer in model.encoder.layer:\n",
    "                            assert hasattr(layer.attention.self, \"one_sided_attn_window_size\")\n",
    "                            layer.attention.self.one_sided_attn_window_size = window_size\n",
    "\n",
    "                with torch.inference_mode():\n",
    "                    num_docs = find_max_docs(model, kwargs)\n",
    "                    pg.set_description(f\"{model_name} {seq_len} {query_len} {window_size} {num_docs}\")\n",
    "                    repeats = 0\n",
    "                    while True:\n",
    "                        try:\n",
    "                            tracker.start_task(\"run inference\")\n",
    "                            torch.cuda.reset_peak_memory_stats()\n",
    "                            start = time.perf_counter()\n",
    "                            inp = {key: expand_tensor(key, tensor, num_docs) for key, tensor in kwargs.items()}\n",
    "                            model(**inp)\n",
    "                            torch.cuda.synchronize()\n",
    "                            model_time = time.perf_counter() - start\n",
    "                            max_mem = torch.cuda.max_memory_allocated()\n",
    "                            emissions = tracker.stop_task()\n",
    "                            model_data.append(\n",
    "                                [\n",
    "                                    model_name,\n",
    "                                    query_len,\n",
    "                                    seq_len,\n",
    "                                    window_size,\n",
    "                                    model_time,\n",
    "                                    max_mem,\n",
    "                                    num_docs,\n",
    "                                    emissions.energy_consumed,\n",
    "                                    emissions.gpu_energy,\n",
    "                                ]\n",
    "                            )\n",
    "                            repeats += 1\n",
    "                            if repeats == repeat:\n",
    "                                break\n",
    "                        except torch.cuda.OutOfMemoryError:\n",
    "                            num_docs -= 1\n",
    "                            \n",
    "model_df = pd.DataFrame(\n",
    "    model_data, \n",
    "    columns=[\n",
    "        \"name\",\n",
    "        \"query_len\",\n",
    "        \"seq_len\",\n",
    "        \"window_size\",\n",
    "        \"time\",\n",
    "        \"space\",\n",
    "        \"num_docs\",\n",
    "        \"total_energy\",\n",
    "        \"gpu_energy\",\n",
    "    ]\n",
    ")\n",
    "model_df.to_json(\"model_df.json\")\n",
    "del model_data\n",
    "model_df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMbPZnfMSvws0JwvcqVVxwQ",
   "gpuType": "T4",
   "mount_file_id": "1O0iTKNqySI_-wIiGMNvaZIVOi33YvwEQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "027aeab48d9a403387130a3de585d81b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_908c49b2fa9c4621869f2fd1659b0f28",
      "placeholder": "",
      "style": "IPY_MODEL_79d0781832824cae9f5ca07b4e1885b6",
      "value": " 570/570 [00:00&lt;00:00, 18.8kB/s]"
     }
    },
    "0c3c140249634e9bade635345ad90513": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0e197aa9568e47fda1148735bc655f45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f98702e17804fc2b03461b24548ed40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10e99217fdda4c2d9029f571256e65d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1154f25e1b434f998fa414ae1ae17976": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10e99217fdda4c2d9029f571256e65d9",
      "placeholder": "",
      "style": "IPY_MODEL_c305b01ab68f421882cfb05e31b966d2",
      "value": "Downloading ()lve/main/config.json: 100%"
     }
    },
    "1a19cbf33bb942548d16b3ae824bb636": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1da9705e393545598647f51a8ebf2048": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1154f25e1b434f998fa414ae1ae17976",
       "IPY_MODEL_47c2890178ad4561a0462b0069447ac8",
       "IPY_MODEL_39c9d17d191848239cadd2257a0dee30"
      ],
      "layout": "IPY_MODEL_1a19cbf33bb942548d16b3ae824bb636"
     }
    },
    "21c99b682cdc4ce89528b45023247c33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30fe3d812b814765840be83290d8338c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39c9d17d191848239cadd2257a0dee30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53d4a79e6ed44b868182d2c65812dd54",
      "placeholder": "",
      "style": "IPY_MODEL_6df2b4addd4644e38a27821acbe28b5e",
      "value": " 794/794 [00:00&lt;00:00, 20.0kB/s]"
     }
    },
    "3ec6d72acf56456ea1517cc41a8cab4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f98702e17804fc2b03461b24548ed40",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_21c99b682cdc4ce89528b45023247c33",
      "value": 570
     }
    },
    "47c2890178ad4561a0462b0069447ac8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af349d82dc1d455badd7891cca8998f5",
      "max": 794,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e119bd9d8a94423db996396ec2d15cd5",
      "value": 794
     }
    },
    "53d4a79e6ed44b868182d2c65812dd54": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ba211e7bdd14afab25ba1662271fe6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ec92227d4d44df7a189e49624abbc75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62a99d84a440457784e63c5221c291da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6df2b4addd4644e38a27821acbe28b5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fa3668da1644401a4294fd2d27911cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62a99d84a440457784e63c5221c291da",
      "placeholder": "",
      "style": "IPY_MODEL_5ba211e7bdd14afab25ba1662271fe6a",
      "value": "Downloading ()lve/main/config.json: 100%"
     }
    },
    "79d0781832824cae9f5ca07b4e1885b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86b9271859614ca79cd3740ecbbe3eac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ec92227d4d44df7a189e49624abbc75",
      "placeholder": "",
      "style": "IPY_MODEL_bd8c05d409b74a59a3fea92f7b46ff00",
      "value": " 694/694 [00:00&lt;00:00, 23.5kB/s]"
     }
    },
    "908c49b2fa9c4621869f2fd1659b0f28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af349d82dc1d455badd7891cca8998f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7892e3b15a448328ccce8e6e05f3951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd8c05d409b74a59a3fea92f7b46ff00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c305b01ab68f421882cfb05e31b966d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da13db9e57ad41929ea0beee0bb030c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddec98ca031d4ed0bdba0e367766d31f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6fa3668da1644401a4294fd2d27911cd",
       "IPY_MODEL_f442d06fdd0a4446b841aebce9e00d94",
       "IPY_MODEL_86b9271859614ca79cd3740ecbbe3eac"
      ],
      "layout": "IPY_MODEL_30fe3d812b814765840be83290d8338c"
     }
    },
    "e119bd9d8a94423db996396ec2d15cd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f18f688ec61e4b99bcf0f4b530fdbe18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f95ff4c899ea40a7ba17a85e0c1a0008",
      "placeholder": "",
      "style": "IPY_MODEL_b7892e3b15a448328ccce8e6e05f3951",
      "value": "Downloading ()lve/main/config.json: 100%"
     }
    },
    "f442d06fdd0a4446b841aebce9e00d94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da13db9e57ad41929ea0beee0bb030c0",
      "max": 694,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0c3c140249634e9bade635345ad90513",
      "value": 694
     }
    },
    "f52dcbfed6354ae19f4560061eab371a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f18f688ec61e4b99bcf0f4b530fdbe18",
       "IPY_MODEL_3ec6d72acf56456ea1517cc41a8cab4d",
       "IPY_MODEL_027aeab48d9a403387130a3de585d81b"
      ],
      "layout": "IPY_MODEL_0e197aa9568e47fda1148735bc655f45"
     }
    },
    "f95ff4c899ea40a7ba17a85e0c1a0008": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
